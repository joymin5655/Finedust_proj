#!/usr/bin/env python3
"""
fetch_openaq.py â€” OpenAQ v3 PM2.5 timeseries collector
-------------------------------------------------------
GitHub Actionsì—ì„œ OPENAQ_API_KEY ì‹œí¬ë¦¿ì„ ì‚¬ìš©í•´ ì‹¤í–‰
ê²°ê³¼ë¬¼:
  app/data/openaq/pm25_years.json   â€” êµ­ê°€/ë„ì‹œë³„ ì—°í‰ê· 
  app/data/openaq/pm25_days.json    â€” ìµœê·¼ 365ì¼ ì¼í‰ê· 
  app/data/openaq/stations.json     â€” ì¸¡ì •ì†Œ ë©”íƒ€

Usage:
  OPENAQ_API_KEY=xxx python3 scripts/python/fetch_openaq.py
"""

import os, json, time, sys
from pathlib import Path
from datetime import datetime, timedelta

try:
    import requests
except ImportError:
    print("requests not installed. Run: pip install requests")
    sys.exit(1)

# â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
API_KEY = os.environ.get("OPENAQ_API_KEY", "").strip()
if not API_KEY:
    print("âŒ OPENAQ_API_KEY not set")
    sys.exit(1)

BASE_URL = "https://api.openaq.org"
HEADERS  = {"X-API-Key": API_KEY, "Accept": "application/json"}
OUT_DIR  = Path(__file__).resolve().parents[2] / "app" / "data" / "openaq"

# â”€â”€ ìˆ˜ì§‘ ëŒ€ìƒ ë„ì‹œ (location id ëŠ” APIë¡œ ì¡°íšŒ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
TARGET_CITIES = [
    {"city": "Seoul",        "country": "KR"},
    {"city": "Busan",        "country": "KR"},
    {"city": "Incheon",      "country": "KR"},
    {"city": "Beijing",      "country": "CN"},
    {"city": "Shanghai",     "country": "CN"},
    {"city": "Tokyo",        "country": "JP"},
    {"city": "Osaka",        "country": "JP"},
    {"city": "Delhi",        "country": "IN"},
    {"city": "Mumbai",       "country": "IN"},
    {"city": "Bangkok",      "country": "TH"},
    {"city": "Singapore",    "country": "SG"},
    {"city": "Taipei",       "country": "TW"},
    {"city": "Jakarta",      "country": "ID"},
    {"city": "London",       "country": "GB"},
    {"city": "Paris",        "country": "FR"},
    {"city": "Berlin",       "country": "DE"},
    {"city": "Madrid",       "country": "ES"},
    {"city": "Warsaw",       "country": "PL"},
    {"city": "New York",     "country": "US"},
    {"city": "Los Angeles",  "country": "US"},
    {"city": "Chicago",      "country": "US"},
    {"city": "Toronto",      "country": "CA"},
    {"city": "Sao Paulo",    "country": "BR"},
    {"city": "Cairo",        "country": "EG"},
    {"city": "Nairobi",      "country": "KE"},
    {"city": "Sydney",       "country": "AU"},
    {"city": "Melbourne",    "country": "AU"},
]

SLEEP_SEC = 0.5   # API rate limit ë°©ì§€


def get_json(url, params=None, retries=3):
    """GET ìš”ì²­ + ì¬ì‹œë„"""
    for attempt in range(retries):
        try:
            r = requests.get(url, headers=HEADERS, params=params, timeout=30)
            if r.status_code == 429:
                wait = 10 * (attempt + 1)
                print(f"  â³ Rate limited, waiting {wait}s...")
                time.sleep(wait)
                continue
            r.raise_for_status()
            return r.json()
        except requests.RequestException as e:
            print(f"  âš ï¸  Attempt {attempt+1} failed: {e}")
            time.sleep(2)
    return None


def find_pm25_sensor(city_name, country_code):
    """ë„ì‹œì—ì„œ PM2.5 ì„¼ì„œ ID ì°¾ê¸°"""
    url = f"{BASE_URL}/v3/locations"
    params = {
        "city": city_name,
        "country_id": country_code,
        "limit": 10,
        "order_by": "lastUpdated",
        "sort_order": "desc"
    }
    data = get_json(url, params)
    if not data or "results" not in data:
        return None, None

    for loc in data["results"]:
        for sensor in loc.get("sensors", []):
            param = sensor.get("parameter", {})
            if param.get("name") == "pm25" or param.get("displayName") == "PM2.5":
                return loc["id"], sensor["id"]
    return None, None


def fetch_sensor_years(sensor_id):
    """ì„¼ì„œë³„ ì—°í‰ê·  ë°ì´í„°"""
    url = f"{BASE_URL}/v3/sensors/{sensor_id}/years"
    params = {"limit": 10}
    data = get_json(url, params)
    if not data:
        return []
    return [
        {
            "year": r.get("period", {}).get("datetimeFrom", {}).get("local", "")[:4],
            "avg":  round(r.get("summary", {}).get("mean", 0), 2),
            "min":  round(r.get("summary", {}).get("min", 0), 2),
            "max":  round(r.get("summary", {}).get("max", 0), 2),
        }
        for r in data.get("results", [])
        if r.get("summary", {}).get("mean")
    ]


def fetch_sensor_days(sensor_id, days=90):
    """ì„¼ì„œë³„ ì¼í‰ê·  ë°ì´í„° (ìµœê·¼ Nì¼)"""
    date_to = datetime.utcnow()
    date_from = date_to - timedelta(days=days)
    url = f"{BASE_URL}/v3/sensors/{sensor_id}/days"
    params = {
        "limit": days,
        "date_from": date_from.strftime("%Y-%m-%dT00:00:00Z"),
        "date_to":   date_to.strftime("%Y-%m-%dT00:00:00Z"),
    }
    data = get_json(url, params)
    if not data:
        return []
    return [
        {
            "date": r.get("period", {}).get("datetimeFrom", {}).get("local", "")[:10],
            "avg":  round(r.get("summary", {}).get("mean", 0), 2),
        }
        for r in data.get("results", [])
        if r.get("summary", {}).get("mean")
    ]


def main():
    print("ğŸŒ OpenAQ PM2.5 Data Collector")
    print("=" * 50)

    OUT_DIR.mkdir(parents=True, exist_ok=True)

    years_out   = []
    days_out    = []
    stations_out = []
    ok = fail = 0

    for target in TARGET_CITIES:
        city    = target["city"]
        country = target["country"]
        print(f"\nğŸ“ {city} ({country})...")

        loc_id, sensor_id = find_pm25_sensor(city, country)
        if not sensor_id:
            print(f"  âŒ No PM2.5 sensor found")
            fail += 1
            time.sleep(SLEEP_SEC)
            continue

        print(f"  âœ… sensor_id={sensor_id}")
        stations_out.append({
            "city": city, "country": country,
            "location_id": loc_id, "sensor_id": sensor_id
        })

        # ì—°í‰ê· 
        year_data = fetch_sensor_years(sensor_id)
        if year_data:
            years_out.append({
                "city": city, "country": country,
                "sensor_id": sensor_id,
                "data": year_data
            })
            print(f"  ğŸ“… {len(year_data)} years of data")
        time.sleep(SLEEP_SEC)

        # ì¼í‰ê· 
        day_data = fetch_sensor_days(sensor_id, 90)
        if day_data:
            days_out.append({
                "city": city, "country": country,
                "sensor_id": sensor_id,
                "data": day_data
            })
            print(f"  ğŸ“… {len(day_data)} days of data")
        time.sleep(SLEEP_SEC)

        ok += 1

    # â”€â”€ ì €ì¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    ts = datetime.utcnow().isoformat() + "Z"

    (OUT_DIR / "pm25_years.json").write_text(
        json.dumps({"updated_at": ts, "count": len(years_out), "data": years_out},
                   ensure_ascii=False, indent=2), encoding="utf-8"
    )
    print(f"\nğŸ’¾ Saved pm25_years.json ({len(years_out)} cities)")

    (OUT_DIR / "pm25_days.json").write_text(
        json.dumps({"updated_at": ts, "count": len(days_out), "data": days_out},
                   ensure_ascii=False, indent=2), encoding="utf-8"
    )
    print(f"ğŸ’¾ Saved pm25_days.json ({len(days_out)} cities)")

    (OUT_DIR / "stations.json").write_text(
        json.dumps({"updated_at": ts, "count": len(stations_out), "stations": stations_out},
                   ensure_ascii=False, indent=2), encoding="utf-8"
    )
    print(f"ğŸ’¾ Saved stations.json ({len(stations_out)} entries)")

    print(f"\nâœ… Done â€” {ok} cities OK, {fail} failed")


if __name__ == "__main__":
    main()
